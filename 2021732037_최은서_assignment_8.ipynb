{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "LHEDxR4JDVFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "dIlvc5roDZwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # numpy를 np로써 import\n",
        "import torch # torch를 import\n",
        "import torch.nn as nn # torch.nn을 nn로써 import\n",
        "import torch.nn.functional as func # torch.nn.functional을 func로써 impot\n",
        "import torch.optim as opt # torch.optimd을 opt로써 import\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # colab을 내 google drive와 연결\n",
        "\n",
        "# Seed 고정\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgMZU9bvDObj",
        "outputId": "37961340-7250-47ae-c00a-246ebaf4e5f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7eefe6f74f10>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 Data loading\n",
        "| $x_1$ | $x_2$ | $y$ |\n",
        "|---|---|---|\n",
        "| 1 | 2 | 0 |\n",
        "| 2 | 3 | 0 |\n",
        "| 3 | 1 | 0 |\n",
        "| 4 | 3 | 1 |\n",
        "| 5 | 3 | 1 |\n",
        "| 6 | 2 | 1 |"
      ],
      "metadata": {
        "id": "BRXO9AjdDcM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data 수동으로 입력하기\n",
        "x_train = torch.FloatTensor([[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]) # 각각 2개의 입력을 x_train변수에 저장\n",
        "y_train = torch.FloatTensor([[0], [0], [0], [1], [1], [1]]) # 1개의 출력을 y_train에 저장\n",
        "\n",
        "print(x_train) # x_train 출력\n",
        "print(x_train.shape) # x_train의 모양 출력\n",
        "print(y_train) # y_train 출력\n",
        "print(y_train.shape) # y_train의 모양 출력\n",
        "\n",
        "# Model 설계\n",
        "class Logistic(nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(num_inputs, num_outputs) #각각의 input과 output에 linear을 취한 값을 self.linear에 넣어준다\n",
        "        self.sigmoid = nn.Sigmoid() # sigmoid 함수 정의\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x)) # 위의 data는 2차이기 때문에 1차 -> 1차 해주기 위해 x에 linear를 취한 값을 sigmoid에 넣어준다\n",
        "\n",
        "# Model 초기화 (입력 dim, 출력 dim)\n",
        "model = Logistic(2, 1) # 입력 : 2 -> 출력 : 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7iGK7ZcDet0",
        "outputId": "40005576-b571-4cf3-c78b-3b093874b3b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [2., 3.],\n",
            "        [3., 1.],\n",
            "        [4., 3.],\n",
            "        [5., 3.],\n",
            "        [6., 2.]])\n",
            "torch.Size([6, 2])\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 Hypothesis, Cost and Optimization\n",
        "* 다음 수식을 만족한다고 가정한다\n",
        "  + Input이 1개(Scalar)인 경우\n",
        "$$ y_{hypo} = H(x) = \\frac{1}{1+e^{-\\alpha x}} $$\n",
        "  + Input이 여러개(Vector)인 경우\n",
        "$$ y_{hypo} = H(X) = \\frac{1}{1+e^{-W^TX}} $$\n",
        "\n",
        "* ex) data가 3개인 경우,\n",
        "  $$ y =  \\frac{1}{1 + e^{-\\begin{bmatrix} w_1 && w_2 && w_3 \\end{bmatrix} \\cdot \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}}} $$\n",
        "  + 이를 만족하는 $W$ 를 구해야 한다\n",
        "* Cost function으로 Binary Cross Entropy를 이용한다\n",
        "$$ -[y_{train}log(y_{hypo}) + (1-y_{train})log(1-y_{hypo})] $$"
      ],
      "metadata": {
        "id": "FLtY6uLjDsSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer 설정 (learning rate = 1로 설정)\n",
        "optimizer = opt.SGD(model.parameters(), lr=1) # 여기서 lr은 계속 수정하면서 cost값이 가장 작을 때를 선정한다\n",
        "\n",
        "# 반복\n",
        "for epoch in range(100): # 100번 반복\n",
        "\n",
        "  # Cost 계산 / mse_loss(가정에의한값, 참값)\n",
        "  y_hypo = model(x_train) # model에 대입한 결과값을 y_hypo에 넣어준다\n",
        "  cost = func.binary_cross_entropy(y_hypo, y_train) # 예상값과 결과값 사이의 binary_cross_entropy의 계산값을 cost에 넣어준\n",
        "\n",
        "  # cost를 이용해 model update\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # 10번 마다 중간결과 출력\n",
        "  if epoch % 10 == 9:\n",
        "    prediction = y_hypo >= torch.FloatTensor([0.5]) # 값이 0.5 이상이면 1, 아니면 0을 출력하게 설정한 값을 prediction에 넣어준다\n",
        "    correct_prediction = prediction.float() == y_train # prediction의 값과 y_train의 값이 같다면 correct_prediction에 대입\n",
        "    accuracy = correct_prediction.sum().item() / len(correct_prediction) # 비율을 accuary(정확도)에 넣어준다\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format(\n",
        "            epoch, 100, cost.item(), accuracy * 100,\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUPU5l43DxBd",
        "outputId": "2814242e-066e-4735-8b09-0e3ae79d3365"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    9/100 Cost: 0.764956 Accuracy 66.67%\n",
            "Epoch   19/100 Cost: 0.596826 Accuracy 83.33%\n",
            "Epoch   29/100 Cost: 0.491604 Accuracy 83.33%\n",
            "Epoch   39/100 Cost: 0.405330 Accuracy 83.33%\n",
            "Epoch   49/100 Cost: 0.323565 Accuracy 83.33%\n",
            "Epoch   59/100 Cost: 0.249201 Accuracy 83.33%\n",
            "Epoch   69/100 Cost: 0.191438 Accuracy 100.00%\n",
            "Epoch   79/100 Cost: 0.159492 Accuracy 100.00%\n",
            "Epoch   89/100 Cost: 0.145180 Accuracy 100.00%\n",
            "Epoch   99/100 Cost: 0.135187 Accuracy 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 Assignment\n",
        "* Data 파일을 이용한 Logistic Regression\n",
        "  - data_logistic_regression.csv을 이용해 학습한다\n",
        "    + 8개의 input, 1개의 output\n",
        "$$ [x_1, ... x_8, y] $$\n",
        "  - Accuracy 75% 이상을 달성한다"
      ],
      "metadata": {
        "id": "mxc9CkCUDzt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # drive mount"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfOHAS1vD2Qu",
        "outputId": "0d007a66-d2f1-4f7a-b68e-997f8b3cfeb4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 import\n",
        "import numpy as np # numpy를 np로써 import\n",
        "import torch # torch를 import\n",
        "import torch.nn as nn # torch.nn을 nn로써 import\n",
        "import torch.nn.functional as func # torch.nn.functional을 func로써 impot\n",
        "import torch.optim as opt # torch.optimd을 opt로써 import"
      ],
      "metadata": {
        "id": "d7fwIIHnD42u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy를 이용해 csv file을 ndarray로 가져온다\n",
        "dataset = np.loadtxt(\n",
        "    '/content/drive/MyDrive/data_logistic_regression.csv',  # 구글드라이브에 있는 파일 가져오기\n",
        "    delimiter=',', # 콤마로 dataset구분\n",
        "    dtype=np.float32) # 데이터 타입을 float 형태로 가져옴\n",
        "np.random.shuffle(dataset) # 순서를 random하게 섞음\n",
        "\n",
        "x_train = torch.FloatTensor(dataset[:,:-1]) # 슬라이스를 이용해 전체중에 앞에 8개는 x에 대입 (input -> 8개)\n",
        "y_train = torch.FloatTensor(dataset[:,[-1]]) # 슬라이스를 이용해 전체중에 뒤에 1개는 y rank=n개로 하기 위해 꾸러미로 묶어서 가져온다 (output -> 1)"
      ],
      "metadata": {
        "id": "GBFGjxlXD9SM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 설계\n",
        "class Logistic(nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(num_inputs, num_outputs) #각각의 input과 output에 linear을 취한 값을 self.linear에 넣어준다\n",
        "        self.sigmoid = nn.Sigmoid() # sigmoid 함수 정의\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x)) # 위의 data는 2차이기 때문에 1차 -> 1차 해주기 위해 x에 linear를 취한 값을 sigmoid에 넣어준다"
      ],
      "metadata": {
        "id": "yjZn9LwsEJN4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 초기화 (입력 dim, 출력 dim)\n",
        "model = Logistic(8, 1) # 입력 : 2 -> 출력 : 1\n",
        "optimizer = opt.SGD(model.parameters(), lr=0.5) # learning rate = 0.5"
      ],
      "metadata": {
        "id": "bUlVkYF2EVtl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer 설정 (learning rate = 1로 설정)\n",
        "optimizer = opt.SGD(model.parameters(), lr=1) # 여기서 lr은 계속 수정하면서 cost값이 가장 작을 때를 선정한다\n",
        "\n",
        "# 반복\n",
        "for epoch in range(100): # 100번 반복\n",
        "\n",
        "  # Cost 계산 / mse_loss(가정에의한값, 참값)\n",
        "  y_hypo = model(x_train) # model에 대입한 결과값을 y_hypo에 넣어준다\n",
        "  cost = func.binary_cross_entropy(y_hypo, y_train) # 예상값과 결과값 사이의 binary_cross_entropy의 계산값을 cost에 넣어준\n",
        "\n",
        "  # cost를 이용해 model update\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # 10번 마다 중간결과 출력\n",
        "  if epoch % 10 == 9:\n",
        "    prediction = y_hypo >= torch.FloatTensor([0.5]) # 값이 0.5 이상이면 1, 아니면 0을 출력하게 설정한 값을 prediction에 넣어준다\n",
        "    correct_prediction = prediction.float() == y_train # prediction의 값과 y_train의 값이 같다면 correct_prediction에 대입\n",
        "    accuracy = correct_prediction.sum().item() / len(correct_prediction) # 비율을 accuary(정확도)에 넣어준다\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format(\n",
        "            epoch, 100, cost.item(), accuracy * 100,\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArEBqp20Ejgf",
        "outputId": "48a28c29-efd6-4f86-805f-5fca17005686"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    9/100 Cost: 0.577979 Accuracy 66.93%\n",
            "Epoch   19/100 Cost: 0.541971 Accuracy 72.20%\n",
            "Epoch   29/100 Cost: 0.520980 Accuracy 75.89%\n",
            "Epoch   39/100 Cost: 0.507753 Accuracy 76.42%\n",
            "Epoch   49/100 Cost: 0.498911 Accuracy 76.94%\n",
            "Epoch   59/100 Cost: 0.492736 Accuracy 77.34%\n",
            "Epoch   69/100 Cost: 0.488279 Accuracy 76.94%\n",
            "Epoch   79/100 Cost: 0.484979 Accuracy 76.94%\n",
            "Epoch   89/100 Cost: 0.482484 Accuracy 76.55%\n",
            "Epoch   99/100 Cost: 0.480566 Accuracy 76.81%\n"
          ]
        }
      ]
    }
  ]
}